{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vpvFSOFYvDqE"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q pypdf\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q openai\n",
        "!pip install -q chromadb\n",
        "!pip install -q langchain_community\n",
        "!pip install -q streamlit_chat\n",
        "!pip install -q langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5VRtc2fSvDqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ecc05a-d595-4960-93d8-687c4e984e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import tempfile\n",
        "from streamlit_chat import message\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "def initialize_session_state():\n",
        "    if \"history\" not in st.session_state:\n",
        "        st.session_state[\"history\"] = []\n",
        "\n",
        "    if \"generated\" not in st.session_state:\n",
        "        st.session_state[\"generated\"] = [\n",
        "            \"Hello! Feel free to ask me any questions.\"\n",
        "        ]\n",
        "\n",
        "    if \"past\" not in st.session_state:\n",
        "        st.session_state[\"past\"] = [\"Hey! ðŸ‘‹\"]\n",
        "\n",
        "\n",
        "def conversation_chat(query, chain, history):\n",
        "    result = chain({\n",
        "        \"question\": query,\n",
        "        \"chat_history\": history\n",
        "    })\n",
        "    history.append((query, result[\"answer\"]))\n",
        "    return result[\"answer\"]\n",
        "\n",
        "\n",
        "def display_chat_history(chain):\n",
        "    reply_container = st.container()\n",
        "    container = st.container()\n",
        "\n",
        "    with container:\n",
        "        with st.form(key=\"my_form\", clear_on_submit=True):\n",
        "            user_input = st.text_input(\n",
        "                \"Question:\",\n",
        "                placeholder=\"Ask about your Documents\",\n",
        "                key=\"input\"\n",
        "            )\n",
        "            submit_button = st.form_submit_button(label=\"Send\")\n",
        "\n",
        "        if submit_button and user_input:\n",
        "            with st.spinner(\"Generating response ......\"):\n",
        "                output = conversation_chat(\n",
        "                    query=user_input,\n",
        "                    chain=chain,\n",
        "                    history=st.session_state[\"history\"]\n",
        "                )\n",
        "\n",
        "            st.session_state[\"past\"].append(user_input)\n",
        "            st.session_state[\"generated\"].append(output)\n",
        "\n",
        "    if st.session_state[\"generated\"]:\n",
        "        with reply_container:\n",
        "            for i in range(len(st.session_state[\"generated\"])):\n",
        "                message(\n",
        "                    st.session_state[\"past\"][i],\n",
        "                    is_user=True,\n",
        "                    key=str(i) + \"_user\",\n",
        "                    avatar_style=\"thumbs\"\n",
        "                )\n",
        "                message(\n",
        "                    st.session_state[\"generated\"][i],\n",
        "                    key=str(i),\n",
        "                    avatar_style=\"fun-emoji\"\n",
        "                )\n",
        "\n",
        "\n",
        "def create_conversational_chain(vector_store):\n",
        "    llm = ChatOpenAI(\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        temperature=0.1,\n",
        "        openai_api_key= st.secrets['OPENAI_API_KEY']\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        return_messages=True\n",
        "    )\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "    return chain\n",
        "\n",
        "\n",
        "def main():\n",
        "    initialize_session_state()\n",
        "    st.title(\"QA with RAG using LangChain and OpenAI Model\")\n",
        "    st.sidebar.title(\"Document Processing\")\n",
        "    uploaded_files = st.sidebar.file_uploader(\n",
        "        \"Upload Files\",\n",
        "        accept_multiple_files=True\n",
        "    )\n",
        "\n",
        "    if uploaded_files:\n",
        "        text = []\n",
        "        for file in uploaded_files:\n",
        "            file_extension = os.path.splitext(file.name)[1]\n",
        "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "                temp_file.write(file.read())\n",
        "                temp_file_path = temp_file.name\n",
        "\n",
        "            loader = None\n",
        "            if file_extension == \".pdf\":\n",
        "                loader = PyPDFLoader(temp_file_path)\n",
        "            elif file_extension == \".docx\" or file_extension == \".doc\":\n",
        "                loader = Docx2txtLoader(temp_file_path)\n",
        "            elif file_extension == \".txt\":\n",
        "                loader = TextLoader(temp_file_path)\n",
        "\n",
        "            if loader:\n",
        "                text.extend(loader.load())\n",
        "                os.remove(temp_file_path)\n",
        "\n",
        "        text_splitter = CharacterTextSplitter(\n",
        "            separator=\"\\n\",\n",
        "            chunk_size=768,\n",
        "            chunk_overlap=128,\n",
        "            length_function=len\n",
        "        )\n",
        "        text_chunks = text_splitter.split_documents(text)\n",
        "\n",
        "        embedding = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            model_kwargs={\"device\": \"cpu\"}\n",
        "        )\n",
        "\n",
        "        vector_store = Chroma.from_documents(\n",
        "            documents=text_chunks,\n",
        "            embedding=embedding,\n",
        "            persist_directory=\"chroma_store\"\n",
        "        )\n",
        "\n",
        "        chain = create_conversational_chain(vector_store=vector_store)\n",
        "\n",
        "        display_chat_history(chain=chain)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dp4DDe2YvDqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5949a74-8643-4e8f-8e58-2e117905d94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.82.190.31:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "  localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20G\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E8l0z3JavDqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c52242a-73c4-4b0e-b580-68f15bdff861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.82.190.31"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}